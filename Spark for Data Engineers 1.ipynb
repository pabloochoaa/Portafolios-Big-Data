{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f560a186-23c4-4152-b8b4-dab9373d3966",
   "metadata": {},
   "source": [
    "# **Reto I**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83c93b-57ee-44e3-8bea-163bd4cd3ffd",
   "metadata": {},
   "source": [
    "### 1. Datasets\n",
    "\n",
    "Los datos de origen constan de dos archivos csv con la misma estructura y tipo de columnas.\n",
    "\n",
    "* trade_details: dataset original con datos reales de operaciones financieras.\n",
    "* trade_details_snapshot: copia de seguridad por posibles perdidas de datos.\n",
    "\n",
    "### 2. Columnas y significado:\n",
    "\n",
    "* mfamily: indica la familia de operaciones a la que pertenece.\n",
    "* mgroup: indica el grupo de operaciones dentro de la familia.\n",
    "* mtype: indica el tipo de operación dentro del grupo.\n",
    "* origin_trade_number: indica el número de la operación de trading (la misma operación puede tener varios números de trading).\n",
    "* origin_contract_number: indica el número de contrato de la operación (igual para todas las operaciones que pertenecen al mismo contrato).\n",
    "* maturity: fecha de finalización del contrato de cada operación.\n",
    "\n",
    "### 3. Descripción del problema:\n",
    "\n",
    "En estos datasets se encuentran varias operaciones financieras de distinto tipo, que diferenciaremos mediante los distintos valores de las columnas mfamily, mgroup y mtype.\n",
    "\n",
    "Existe un cierto tipo de operaciones especiales, llamadas FXSwaps. Estas pueden ser diferenciadas por medio de los siguientes valores:\n",
    "\n",
    "**mfamily = CURR** \\\n",
    "**mgroup = FXD** \\\n",
    "**mtype = SWLEG**\n",
    "\n",
    "Podemos ver en nuestro dataset que estas operaciones aparecen duplicadas, es decir, con el mismo **origin_contract_number** aunque distinto **origin_trade_number**. De estas operaciones duplicadas en origen, queremos obtener solo una de ellas.\n",
    "\n",
    "La forma para decidir cuál de las operaciones nos interesa obtener es mediante la columna *maturity*. De ambas operaciones de trading (distinto origin_trade_number) para un mismo contrato (origin_contract_number), queremos obtener solo la *long leg*, es decir, la que tiene una mayor fecha de vencimiento (fecha más actual de la columna maturity).\n",
    "\n",
    "Existe un cierto problema en nuestro dataset trade_details que tendremos que solucionar. Podemos ver que para algunas operaciones el campo maturity vendrá como *null*, es decir, sin informar. En estos casos, deberemos buscar esa operacion en el dataset trade_details_snapshot y el respectivo campo maturity para poder saber cuál de las dos operaciones es la *long leg* y filtrar la *short leg* \n",
    "\n",
    "**NOTA: Si se quiere conocer más el significado de estas operaciones financieras: https://es.wikipedia.org/wiki/Swap_(finanzas)**\n",
    "\n",
    "### 4. Reto:\n",
    "\n",
    "* Obtener un dataframe final donde tengamos todas las operaciones originales excepto los short leg de los contratos tipo FXSwap.\n",
    "* Aunque usemos el valor de la columna maturity del dataset trade_details_snapshot en los casos que venga en la trade_details a *null*, en el dataframe final deberá venir con el valor original de trade_details.\n",
    "* Hacerlo de la manera más eficiente posible a nivel computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b53f96-7b68-4b33-a20b-84fd8dbd0e1a",
   "metadata": {},
   "source": [
    "### Inicialización de SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5da8fad-c1ee-42ad-88ba-1c6587e6de5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.sql.types._\r\n",
       "import org.apache.spark.sql.DataFrame\r\n",
       "import org.apache.spark.sql.expressions.Window\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2bedc3f2\r\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "                        .appName(\"Reto 1\")\n",
    "                        .master(\"local\")\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c747da1-d0a9-4499-9196-dd0ea980cb5b",
   "metadata": {},
   "source": [
    "### Carga de CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18334cd9-be3c-44e8-a9c3-417030a844e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trade_details: org.apache.spark.sql.DataFrame = [mfamily: string, mgroup: string ... 4 more fields]\r\n",
       "trade_details_snapshot: org.apache.spark.sql.DataFrame = [mfamily: string, mgroup: string ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trade_details = spark.read.format(\"csv\")\n",
    "                              .option(\"header\", \"true\")\n",
    "                              .option(\"delimiter\", \";\")\n",
    "                              .load(\"Desktop/Big Data/Retos Big Data/Spark for Data Engineers/reto1/trade_details.csv\")\n",
    "\n",
    "val trade_details_snapshot = spark.read.format(\"csv\")\n",
    "                                       .option(\"header\", \"true\")\n",
    "                                       .option(\"delimiter\", \";\")\n",
    "                                       .load(\"Desktop/Big Data/Retos Big Data/Spark for Data Engineers/reto1/trade_details_snapshot.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71edae2e-43e8-4b7a-8fdd-eea896cae503",
   "metadata": {},
   "source": [
    "### Resultado:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab4c7c-65aa-4b54-bd14-7479a67893fa",
   "metadata": {},
   "source": [
    "**INSTRUCCIONES**: El DataFrame resultante debe almacenarse en la variable `resultado`, sustituyendo el valor `None` por el código que consideréis oportuno. De esta forma podréis comprobar si el resultado es correcto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3f6376b-fa7c-4226-a736-2c4f3b870a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [mfamily: string, mgroup: string ... 4 more fields]\r\n",
       "origin_contract_number: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [origin_contract_number: string, origin_trade_number: string]\r\n",
       "list_OCN: List[String] = List(18724280, 21622649, 19883451, 19622128, 19622128, 19883451, 21622649, 18622136, 18724280, 18622136)\r\n",
       "getLongLeg: (ds: org.apache.spark.sql.DataFrame, list: List[String])List[String]\r\n",
       "longLeg: List[String] = List(19772400, 22798005, 20980932, 20665178, 20665178, 20980932, 22798005, 19665186, 19772400, 19665186)\r\n",
       "aux: List[org.apache.spark.sql.Row] = List([IRD,BOND,null,316391872,678876251,2021-09-22], [CURR,FXD,FXD,32734782,54853428,2021-09-22], [IRD,LN_BR,null,1111,2222,2022-10-06], [IRD,IRS,null,22222...\r\n"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var data = trade_details.where($\"mfamily\" === \"CURR\" && $\"mgroup\" === \"FXD\" && $\"mtype\" === \"SWLEG\")\n",
    "\n",
    "val origin_contract_number = data.select(\"origin_contract_number\", \"origin_trade_number\").distinct()\n",
    "val list_OCN = origin_contract_number.map(r => r.getString(0)).collect.toList\n",
    "\n",
    "\n",
    "def getLongLeg(ds: DataFrame, list: List[String]): List[String] ={\n",
    "    var aux : String = \"\"\n",
    "    var longLegOTN: List[String] = List()\n",
    "    var l: List[Any] = List()\n",
    "    \n",
    "    for(aux <- list){\n",
    "         if(!ds.where($\"origin_contract_number\" === aux && $\"maturity\" === \"NULL\").isEmpty){\n",
    "             l = trade_details_snapshot.where(col(\"origin_contract_number\") === aux).orderBy(desc(\"maturity\")).select(\"origin_trade_number\").take(1).toList\n",
    "             longLegOTN = longLegOTN.:+(l(0).toString.substring(1,l(0).toString.length-1))\n",
    "         }else{\n",
    "             l = ds.where(col(\"origin_contract_number\") === aux).orderBy(desc(\"maturity\")).select(\"origin_trade_number\").take(1).toList\n",
    "             longLegOTN = longLegOTN.:+(l(0).toString.substring(1,l(0).toString.length-1))\n",
    "         }\n",
    "    }\n",
    "    \n",
    "    longLegOTN\n",
    "}\n",
    "\n",
    "var longLeg = getLongLeg(origin_contract_number, list_OCN)\n",
    "var aux = data.collect.toList\n",
    "var res: List[String] = List()\n",
    "\n",
    "for(it <- aux){\n",
    "   if(longLeg.contains(it(3))){\n",
    "       res = res.:+(it.toString.substring(1,it.toString.length-1))\n",
    "   }\n",
    "}\n",
    "aux = trade_details.where( $\"mtype\" =!= \"SWLEG\" || col(\"mtype\").isNull).collect.toList\n",
    "\n",
    "for(it <- aux){\n",
    "       res = res.+:(it.toString.substring(1,it.toString.length-1))\n",
    " \n",
    "}\n",
    "\n",
    "val resultado = res\n",
    "\n",
    "//not very efficient working with lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ecabedfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-------------------+----------------------+----------+\n",
      "|mfamily|mgroup|mtype|origin_trade_number|origin_contract_number|  maturity|\n",
      "+-------+------+-----+-------------------+----------------------+----------+\n",
      "|    IRD|    CF| null|           20513130|              19433281|2021-07-06|\n",
      "|    IRD|   IRS| null|          555111222|             555111222|      NULL|\n",
      "|    IRD|  BOND| null|          316391872|             678876251|2021-09-22|\n",
      "|    EQD| EQUIT|  FWD|           10000001|              10000001|2019-07-02|\n",
      "|   CURR|   FXD|SWLEG|           20665178|              19622128|2020-12-30|\n",
      "|    IRD|   IRS| null|           33333333|              33333333|2024-10-15|\n",
      "|    IRD|   IRS| null|          444111222|             444111222|      NULL|\n",
      "|    IRD|    CF| null|           20533916|              19453781|2023-07-06|\n",
      "|    IRD|   IRS| null|           18343978|              17356077|2024-10-15|\n",
      "|    IRD| LN_BR| null|           14596583|              13774383|2020-12-29|\n",
      "|   CURR|   FXD|SWLEG|           22798005|              21622649|      NULL|\n",
      "|    IRD|   IRS| null|          111222333|             111222333|2024-10-15|\n",
      "|    IRD|  BOND|  FWD|           10000009|              10000009|2021-06-12|\n",
      "|    IRD|   IRS| null|          222333111|             222333111|2020-12-30|\n",
      "|   CURR|   FXD|SWLEG|           20980932|              19883451|      NULL|\n",
      "|    IRD|   IRS| null|          556111214|             556111214|      NULL|\n",
      "|    IRD|   IRS| null|           21183317|              20077630|2040-07-13|\n",
      "|    SCF|   SCF|  SCF|            3815982|               3672136|      NULL|\n",
      "|    IRD|   IRS| null|            2222222|               2222222|2024-10-15|\n",
      "|    IRD|   IRS| null|          333111222|             333111222|2020-12-12|\n",
      "+-------+------+-----+-------------------+----------------------+----------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "td_snapshot: org.apache.spark.sql.DataFrame = [mfamily_snapshot: string, mgroup_snapshot: string ... 4 more fields]\r\n",
       "data: org.apache.spark.sql.DataFrame = [mfamily: string, mgroup: string ... 6 more fields]\r\n",
       "data: org.apache.spark.sql.DataFrame = [mfamily: string, mgroup: string ... 6 more fields]\r\n",
       "window: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@6efa422e\r\n",
       "data: org.apache.spark.sql.DataFrame = [mfamily: string, mgroup: string ... 6 more fields]\r\n",
       "data: org.apache.spark.sql.DataFrame = [mfamily: string, mgroup: string ... 6 more fields]\r\n",
       "resultado: org.apache.spark.sql.DataFrame = [mfamily: string, mgroup: string ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var td_snapshot = trade_details_snapshot.withColumnRenamed(\"origin_contract_number\", \"OCN_snapshot\")\n",
    "                                        .withColumnRenamed(\"origin_trade_number\", \"OTN_snapshot\")\n",
    "                                        .withColumnRenamed(\"maturity\", \"maturity_snapshot\")\n",
    "                                        .withColumnRenamed(\"mfamily\", \"mfamily_snapshot\")\n",
    "                                        .withColumnRenamed(\"mgroup\", \"mgroup_snapshot\")\n",
    "                                        .withColumnRenamed(\"mtype\", \"mtype_snapshot\")\n",
    "\n",
    "var data = trade_details.join(td_snapshot,\n",
    "                              trade_details(\"origin_contract_number\") === td_snapshot(\"OCN_snapshot\")\n",
    "                              && trade_details(\"origin_trade_number\") === td_snapshot(\"OTN_snapshot\"), \"left\")\n",
    "\n",
    "data = data.drop(data(\"OTN_snapshot\"))\n",
    "           .drop(data(\"OCN_snapshot\"))\n",
    "           .drop(data(\"mfamily_snapshot\"))\n",
    "           .drop(data(\"mgroup_snapshot\"))\n",
    "           .drop(data(\"mtype_snapshot\"))\n",
    "\n",
    "//data.show(5, 25, true)\n",
    "\n",
    "val window = Window.partitionBy(\"origin_contract_number\")\n",
    "\n",
    "data = data.withColumn(\"long_leg\", max(\"maturity_snapshot\").over(window))\n",
    "\n",
    "data = data.where(col(\"mtype\") =!= \"SWLEG\" || col(\"mtype\").isNull ||  col(\"mtype\") === \"SWLEG\" && col(\"maturity_snapshot\") === col(\"long_leg\"))\n",
    "data.drop(data(\"maturity_snapshot\")).drop(data(\"long_leg\")).show()\n",
    "\n",
    "var result = data\n",
    "\n",
    "//more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe1f62-5956-4e00-9024-f3dc59db3238",
   "metadata": {},
   "source": [
    "Ejecuta la siguiente celda (no modifiques su código) y te dirá si tu solución es correcta o no. En caso de ser correcta, se ejecutará correctamente y no mostrará nada, pero si no lo es mostrará un error. Además de esas pruebas, se realizarán algunas más (ocultas) a la hora de puntuar el ejercicio, pero evaluar dicha celda es un indicador bastante fiable acerca de si realmente has implementado la solución correcta o no.\n",
    "\n",
    "Execute the following cell (don't modify its code) and it will tell you if your solution is correct or not. If its correct, it will show nothing, but if not it will show an error. More tests will be done, but this one indicates in a very reliable way if the implementation is correct or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dadcb308-a425-4812-81ba-d02df23a206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(result.count() == 26)\n",
    "assert(result.orderBy(\"origin_contract_number\").collect()(24)(4) == \"564367838\")\n",
    "assert(result.orderBy(\"origin_contract_number\").collect()(19)(5) == \"NULL\")\n",
    "assert(result.orderBy(\"origin_trade_number\").collect()(16)(5) == \"NULL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
